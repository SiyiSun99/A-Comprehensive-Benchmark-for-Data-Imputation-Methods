{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4123ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from missingpy import MissForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d738a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mache = ['MCAR','MAR','MNAR']\n",
    "missing_ratio = [10,30,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482f260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing ratio is 10.3%\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "data_it_url = 'data_stored/data_miss/' + missing_mache[i] + '/Case11/miss' + str(missing_ratio[j]) + '/' + str(k) + '.csv'\n",
    "data_it = pd.read_csv(data_it_url)\n",
    "# missing ratio\n",
    "missing_amount = []\n",
    "for c in range(8):\n",
    "    missing_num = sum(pd.isnull(data_it.iloc[:,c]))\n",
    "    missing_amount.append(missing_num)\n",
    "total_missing_ratio = sum(missing_amount)/(4177*8)\n",
    "print(\"The missing ratio is {0:.3}%\".format(total_missing_ratio * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f633e121",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h2/jc_81dgs6w1018xl4f_8h5gr0000gp/T/ipykernel_98311/3522233918.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMissForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m341\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/missingpy/missforest.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, cat_vars)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Check data integrity and calling arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         force_all_finite = False if self.missing_values in [\"NaN\",\n\u001b[1;32m    438\u001b[0m                                                             np.nan] else True\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         X = check_array(X, accept_sparse=False, dtype=np.float64,\n\u001b[0m\u001b[1;32m    441\u001b[0m                         force_all_finite=force_all_finite, copy=self.copy)\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;31m# Check for +/- inf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"
     ]
    }
   ],
   "source": [
    "imputer = MissForest(random_state = 341)\n",
    "imputer.fit(data_it, cat_vars = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3038c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_split_con_cat_column(df_miss):\n",
    "    columns = df_miss.columns\n",
    "    columns_split = [i.split('_') for i in columns]\n",
    "    con = []\n",
    "    cat = []\n",
    "    for index, i in enumerate(columns_split):\n",
    "        if i[0][0:3] == 'con':\n",
    "            con.append(columns[index])\n",
    "        elif i[0][0:3] == 'cat':\n",
    "            cat.append(columns[index])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return con, cat\n",
    "\n",
    "# def return_dictionary_column(column_unique):\n",
    "#     dict_res = {}\n",
    "#     dict_rev = {}\n",
    "#     for index, i in enumerate(column_unique):\n",
    "#         dict_res[i] = index\n",
    "#         dict_rev[index] = i\n",
    "    \n",
    "#     return dict_res, dict_rev \n",
    "\n",
    "# def return_encode_column(column_m, dictionary, mode):\n",
    "#     column_encode = []\n",
    "    \n",
    "#     if mode == 'one_hot':\n",
    "#         for index, i in enumerate(column_m):\n",
    "#             if i == np.nan or str(i) == 'nan':\n",
    "#                 column_encode.append([np.nan for j in range(len(dictionary))])\n",
    "#             else:\n",
    "#                 column_encode.append(list(np.eye(len(dictionary))[dictionary[i]]))\n",
    "                \n",
    "#         array_encode = np.array(column_encode, dtype = np.float32)\n",
    "    \n",
    "#     elif mode == 'embedding':\n",
    "#         for index, i in enumerate(column_m):\n",
    "#             if i == np.nan or str(i) == 'nan':\n",
    "#                 column_encode.append([np.nan for j in range(len(dictionary))])\n",
    "#             else:\n",
    "#                 column_encode.append(list(np.eye(len(dictionary))[dictionary[i]] * 2. - 1.))\n",
    "                \n",
    "#         array_encode = np.array(column_encode, dtype = np.float32)\n",
    "        \n",
    "#     return array_encode\n",
    "    \n",
    "    \n",
    "# def return_normalized_column(column_m, column_i, mode):\n",
    "    \n",
    "#     if mode == 'one_hot':\n",
    "#         max_m = np.nanmax(np.array(column_m))\n",
    "#         min_m = np.nanmin(np.array(column_m))\n",
    "#         max_i = np.max(np.array(column_i))\n",
    "#         min_i = np.min(np.array(column_i))\n",
    "#         if min_m != max_m:\n",
    "#             column_m_normalize = [(i - min_m)/(max_m - min_m) for i in column_m]\n",
    "#             column_m_normalize = [i for i in column_m_normalize]\n",
    "#         else:\n",
    "#             column_m_normalize = [i * 0. for i in column_m]\n",
    "#     elif mode == 'embedding':\n",
    "#         max_m = np.nanmax(np.array(column_m))\n",
    "#         min_m = np.nanmin(np.array(column_m))\n",
    "#         max_i = np.max(np.array(column_i))\n",
    "#         min_i = np.min(np.array(column_i))\n",
    "#         if min_m != max_m:\n",
    "#             column_m_normalize = [(i - min_m)/(max_m - min_m) for i in column_m]\n",
    "#             column_m_normalize = [i * 2. - 1. for i in column_m_normalize]\n",
    "#         else:\n",
    "#             column_m_normalize = [0. for i in column_m]\n",
    "    \n",
    "#     array_m_normalized = np.array(column_m_normalize, np.float32).reshape(len(column_m_normalize), 1)\n",
    "    \n",
    "#     return array_m_normalized, max_m, min_m, max_i, min_i\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc7ac8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argmax(missing_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53c25697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat_Sex']\n"
     ]
    }
   ],
   "source": [
    "con, cat = return_split_con_cat_column(df_miss = data_it)\n",
    "# Define the labels, location below:\n",
    "labels = []\n",
    "labels_ori = []\n",
    "locations = []\n",
    "attach = []\n",
    "\n",
    "# Start encode the cat variables:\n",
    "#print(\"Now, the preprocessing of data have already started, with mode: \" + mode)\n",
    "for index, i in enumerate(data_it.columns):\n",
    "    if i in cat:\n",
    "        column_m = df_miss[i].to_list()\n",
    "        column_i = df_full[i].to_list()\n",
    "        columns_m_unique = list(set([i for i in column_m if str(i) != 'nan']))\n",
    "        columns_i_unique = list(set([i for i in column_i]))\n",
    "        dict_res_column, dict_rev_column = return_dictionary_column(column_unique = columns_m_unique)\n",
    "        dictori_res_column, dictori_rev_column = return_dictionary_column(column_unique = columns_i_unique)\n",
    "        column_encode = return_encode_column(column_m = column_m, dictionary = dict_res_column, mode = mode)\n",
    "        locations.append(column_encode.shape[1])\n",
    "        labels.append(['cat', [dict_res_column, dict_rev_column]])\n",
    "        labels_ori.append(['cat', [dictori_res_column, dictori_rev_column]])\n",
    "        attach.append(['cat', columns_i_unique]) \n",
    "    elif i in con:\n",
    "        column_m = df_miss[i].to_list()\n",
    "        column_i = df_full[i].to_list()\n",
    "        column_encode, max_m, min_m, max_i, min_i = return_normalized_column(column_m = column_m, column_i = column_i, mode = mode)\n",
    "        locations.append(column_encode.shape[1])\n",
    "        labels.append(['con', [max_m, min_m]])\n",
    "        labels_ori.append(['con', [max_i, min_i]])\n",
    "        attach.append(['con', [max_m, min_m]])\n",
    "\n",
    "    array_encode_column = np.array(column_encode, np.float32)\n",
    "\n",
    "    if index == 0:\n",
    "        array_result = array_encode_column\n",
    "    else:\n",
    "        array_result = np.concatenate((array_result, array_encode_column), axis = 1)\n",
    "        locations[-1] = locations[-1] + locations[-2]\n",
    "#print(\"Now, the preprocessing of data had been finished.\\n\")   \n",
    "return array_result, df_full.columns, locations, labels, df_full, df_miss, attach, labels_ori"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
